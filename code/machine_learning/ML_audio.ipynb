{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749cbdfd",
   "metadata": {},
   "source": [
    "# [Machine Learning - Audio Classification Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7810f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all library\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import scipy.io.wavfile\n",
    "import spafe.utils.vis as vis\n",
    "from spafe.features.gfcc import gfcc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bf380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv=pd.read_csv(\"../../dataset/train.csv\") #read the train csv file\n",
    "test_csv=pd.read_csv(\"../../dataset/test.csv\") #read the test csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264a138",
   "metadata": {},
   "source": [
    "## USER has to initialize these variables when changing feature extraction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c2cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array initialization\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fb2d7",
   "metadata": {},
   "source": [
    "## USER INPUT: You can change sampling rate here. Please input 8000 or 16000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0be535",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000 #set sampling rate OPTION : 8000 / 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7804331",
   "metadata": {},
   "source": [
    "# OPTION: USER has to run manually from here to change feature extraction methods\n",
    "### 4 OPTIONS : 1) MFCC  2) MEL SPECTROGRAM  3) LOG-MEL SPECTROGRAM  4)GTCC\n",
    "## Run the corresponding cell.\n",
    "\n",
    "## OPTION 1) Run this cell for MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1cdd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file in enumerate(train_csv['file_name']):\n",
    "    audio, sr = librosa.load(f'../../dataset/audio/{file}', sr=sr) #load each file\n",
    "    audio = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40) #feature extraction method - MFCC\n",
    "    x_train.append(audio.flatten()) #flatten\n",
    "    y_train.append(train_csv['label'].iloc[idx]) #The label values in csv are extracted by index and added to the list.\n",
    "    \n",
    "for idx, file in enumerate(test_csv['file_name']):\n",
    "    audio, sr = librosa.load(f'../../dataset/audio/{file}', sr=sr) #load each file\n",
    "    audio = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40) #feature extraction method - MFCC\n",
    "    x_test.append(audio.flatten()) #flatten\n",
    "    y_test.append(test_csv['label'].iloc[idx]) #The label values in csv are extracted by index and added to the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e583f",
   "metadata": {},
   "source": [
    "## OPTION 2) Run this cell for Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file in enumerate(train_csv['file_name']):\n",
    "    audio, sr = librosa.load(f'../../dataset/audio/{file}', sr=sr) #load each file\n",
    "    audio = librosa.feature.melspectrogram(audio, sr) #feature extraction method - mel spectrogram\n",
    "    x_train.append(audio.flatten()) #flatten\n",
    "    y_train.append(train_csv['label'].iloc[idx]) #The label values in csv are extracted by index and added to the list.\n",
    "    \n",
    "for idx, file in enumerate(test_csv['file_name']):\n",
    "    audio, sr = librosa.load(f'../../dataset/audio/{file}', sr=sr) #load each file\n",
    "    audio = librosa.feature.melspectrogram(audio, sr) #feature extraction method - mel spectrogram\n",
    "    x_test.append(audio.flatten()) #flatten\n",
    "    y_test.append(test_csv['label'].iloc[idx]) #The label values in csv are extracted by index and added to the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2224c8e",
   "metadata": {},
   "source": [
    "## OPTION 3) Run this cell for Log-Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b625749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file in enumerate(train_csv['file_name']):\n",
    "    audio, sr = librosa.load(f'../../dataset/audio/{file}', sr=sr)  #load each file\n",
    "    audio = librosa.feature.melspectrogram(audio, sr) \n",
    "    audio = librosa.power_to_db(audio) #feature extraction method - log-mel spectrogram\n",
    "    x_train.append(audio.flatten()) #flatten\n",
    "    y_train.append(train_csv['label'].iloc[idx]) #The label values in csv are extracted by index and added to the list\n",
    "    \n",
    "for idx, file in enumerate(test_csv['file_name']):\n",
    "    audio, sr = librosa.load(f'../../dataset/audio/{file}', sr=sr) #load each file\n",
    "    audio = librosa.feature.melspectrogram(audio, sr)\n",
    "    audio = librosa.power_to_db(audio) #feature extraction method - log-mel spectrogram\n",
    "    x_test.append(audio.flatten()) #flatten\n",
    "    y_test.append(test_csv['label'].iloc[idx]) #The label values in csv are extracted by index and added to the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0720f2",
   "metadata": {},
   "source": [
    "## OPTION 4) Run this cell for GTCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e3315a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file in enumerate(train_csv['file_name']):\n",
    "    fs,sig = scipy.io.wavfile.read(f'../../dataset/audio/{file}')  #load each file\n",
    "    gfccs  = gfcc(sig,num_ceps=200, nfilts =200,fs=sr) #feature extraction method - GTCC\n",
    "    audio = np.array(gfccs)\n",
    "    audio = audio.reshape(audio.shape[0], audio.shape[1], 1) #reshape\n",
    "    x_train.append(audio.flatten()) #flatten\n",
    "    y_train.append(train_csv['label'].iloc[idx]) #The label values in csv are extracted by index and added to the list\n",
    "\n",
    "for idx, file in enumerate(test_csv['file_name']):\n",
    "    fs,sig = scipy.io.wavfile.read(f'../../dataset/audio/{file}') #load each file\n",
    "    gfccs  = gfcc(sig,num_ceps=200, nfilts =200,fs=sr) #feature extraction method - GTCC\n",
    "    audio = np.array(gfccs)\n",
    "    audio = audio.reshape(audio.shape[0], audio.shape[1], 1) #reshape\n",
    "    x_test.append(audio.flatten()) #flatten\n",
    "    y_test.append(test_csv['label'].iloc[idx] )#The label values in csv are extracted by index and added to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b1ede",
   "metadata": {},
   "source": [
    "Feature exatraction OPTION END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff1251d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "x_train = scaler.fit_transform(x_train) # Standardize train data\n",
    "x_test = scaler.transform(x_test) # Standardize test data\n",
    "\n",
    "x_train=pd.DataFrame(x_train) # to dataframe\n",
    "y_train=pd.DataFrame(y_train) # to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f8c95",
   "metadata": {},
   "source": [
    "# OPTION: USER has to run manually from here to change models\n",
    "### 4 OPTIONS : 1) SVM 2) MLP 3) KNN 4)GNB\n",
    "## Run the corresponding cell.\n",
    "\n",
    "## OPTION 1) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3866ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "#Create a SVM Classifier\n",
    "model = svm.SVC(kernel = 'rbf', C = 1,verbose=True, probability=True)\n",
    "#Train the model using the training sets\n",
    "model = model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda8759b",
   "metadata": {},
   "source": [
    "## OPTION 2) MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e2b5542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.52808969\n",
      "Validation score: 0.834783\n",
      "Iteration 2, loss = 0.41441382\n",
      "Validation score: 0.865217\n",
      "Iteration 3, loss = 0.35805459\n",
      "Validation score: 0.878261\n",
      "Iteration 4, loss = 0.32066045\n",
      "Validation score: 0.865217\n",
      "Iteration 5, loss = 0.29370508\n",
      "Validation score: 0.869565\n",
      "Iteration 6, loss = 0.27120280\n",
      "Validation score: 0.856522\n",
      "Iteration 7, loss = 0.25205152\n",
      "Validation score: 0.865217\n",
      "Iteration 8, loss = 0.23472639\n",
      "Validation score: 0.856522\n",
      "Iteration 9, loss = 0.21944806\n",
      "Validation score: 0.865217\n",
      "Iteration 10, loss = 0.20571244\n",
      "Validation score: 0.856522\n",
      "Iteration 11, loss = 0.19320501\n",
      "Validation score: 0.852174\n",
      "Iteration 12, loss = 0.18146357\n",
      "Validation score: 0.852174\n",
      "Iteration 13, loss = 0.17169639\n",
      "Validation score: 0.847826\n",
      "Iteration 14, loss = 0.16240627\n",
      "Validation score: 0.852174\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "#Create a MLP Classifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(10,),activation='logistic',\n",
    "                    solver='sgd', alpha=0.01, batch_size=10,\n",
    "                    learning_rate_init=0.001, max_iter=70,\n",
    "                    early_stopping=True, verbose= True)\n",
    "#Train the model using the training sets\n",
    "model = model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080f241",
   "metadata": {},
   "source": [
    "## OPTION 3) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4f1292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors = 5)\n",
    "#Train the model using the training sets\n",
    "model = model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b03269",
   "metadata": {},
   "source": [
    "## OPTION 4) GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df34def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "#Train the model using the training sets\n",
    "model=model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc262d96",
   "metadata": {},
   "source": [
    "# Evalution Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de63648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc :  0.8015665796344648\n",
      "AUC :  0.8453714511956204\n",
      "CEL :  6.15587084097439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79       369\n",
      "           1       0.80      0.83      0.81       397\n",
      "\n",
      "    accuracy                           0.80       766\n",
      "   macro avg       0.80      0.80      0.80       766\n",
      "weighted avg       0.80      0.80      0.80       766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test) # model predict\n",
    "y_prob = model.predict_proba(x_test) # calculate probability\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_prob[:,1])\n",
    "AUC = metrics.auc(fpr, tpr) # calculate AUC\n",
    "\n",
    "print('accuracy : ', accuracy_score(y_test,y_pred)) # print accuracy\n",
    "print('AUC : ', AUC) # print AUC\n",
    "print(classification_report(y_test, y_pred)) # print f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35dadf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
